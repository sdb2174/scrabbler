{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-02 14:35:08 INFO: loading saved dictionary file...\n",
      "Scrabble game initialized\n"
     ]
    }
   ],
   "source": [
    "RACK_MAX = 7\n",
    "FV_WEIGHT_NUM = 234\n",
    "\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import scrabbler as sc\n",
    "from scrabbler.dictionary import Dictionary\n",
    "import utilities.logger as logger\n",
    "\n",
    "RACK_MAX = 7\n",
    "\n",
    "LETTER_VALUE = {}\n",
    "with open(\"resources/scrabble/tile_list.txt\") as f:\n",
    "    for line in f:\n",
    "        (key, val) = line.split()\n",
    "        LETTER_VALUE[key] = int(val)\n",
    "\n",
    "script_dir = os.path.dirname(\"scrabble_dqn.ipynb\")\n",
    "resource_dir = os.path.join(script_dir, \"resources\")\n",
    "resource_directory = os.path.join(resource_dir, \"scrabble\")\n",
    "saved_dictionary_path = os.path.join(resource_directory, \"dictionary.p\")\n",
    "\n",
    "logger.info(\"loading saved dictionary file...\")\n",
    "global_dictionary = Dictionary.load_from_pickle(saved_dictionary_path)\n",
    "bag_o = [\"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\",\n",
    "         \"B\", \"B\",\n",
    "         \"C\", \"C\",\n",
    "         \"D\", \"D\", \"D\", \"D\",\n",
    "         \"E\", \"E\", \"E\", \"E\", \"E\", \"E\", \"E\", \"E\", \"E\", \"E\", \"E\", \"E\",\n",
    "         \"F\", \"F\",\n",
    "         \"G\", \"G\", \"G\",\n",
    "         \"H\", \"H\",\n",
    "         \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\",\n",
    "         \"J\",\n",
    "         \"K\",\n",
    "         \"L\", \"L\", \"L\", \"L\",\n",
    "         \"M\", \"M\",\n",
    "         \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",\n",
    "         \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\",\n",
    "         \"P\", \"P\",\n",
    "         \"Q\",\n",
    "         \"R\", \"R\", \"R\", \"R\", \"R\", \"R\",\n",
    "         \"S\", \"S\", \"S\", \"S\",\n",
    "         \"T\", \"T\", \"T\", \"T\", \"T\", \"T\",\n",
    "         \"U\", \"U\", \"U\", \"U\",\n",
    "         \"V\", \"V\",\n",
    "         \"W\", \"W\",\n",
    "         \"X\",\n",
    "         \"Y\", \"Y\",\n",
    "         \"Z\"]\n",
    "\n",
    "\n",
    "print(\"Scrabble game initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class contains information and control flow for an agent to make decisions based off experiences using DQN\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.n_actions = action_size \n",
    "        # we define some parameters and hyperparameters:\n",
    "        # \"lr\" : learning rate\n",
    "        # \"gamma\": discounted factor\n",
    "        # \"exploration_proba_decay\": decay of the exploration probability\n",
    "        # \"batch_size\": size of experiences we sample to train the DNN\n",
    "        self.lr = 0.001\n",
    "        self.gamma = 0.99\n",
    "        self.exploration_proba = 1.0\n",
    "        self.exploration_proba_decay = 0.005 \n",
    "        self.batch_size = 32 \n",
    "\n",
    "        # We define our memory buffer where we will store our experiences\n",
    "        # We stores only the 2000 last time steps\n",
    "        self.memory_buffer= list()\n",
    "        self.max_memory_buffer = 30000\n",
    "        \n",
    "        # We creaate our model having to hidden layers of 24 units (neurones)\n",
    "        # The first layer has the same size as a state size\n",
    "        # The last layer has the size of actions space\n",
    "        self.model = Sequential([\n",
    "            Dense(units=24,input_dim=state_size, activation = 'relu'),\n",
    "            Dense(units=24,activation = 'relu'),\n",
    "            Dense(units=action_size, activation = 'linear')\n",
    "        ])\n",
    "        self.model.compile(loss=\"mse\",\n",
    "                      optimizer = Adam(learning_rate=self.lr))\n",
    "        \n",
    "    # The agent computes the action to perform given a state \n",
    "    def compute_action(self, current_state):\n",
    "        # epsilon greedy policy:\n",
    "        if np.random.uniform(0,1) < self.exploration_proba:\n",
    "            return np.random.choice(range(self.n_actions))\n",
    "        q_values = self.model.predict(current_state)[0]\n",
    "        return np.argmax(q_values)\n",
    "    \n",
    "    # when an episode is finished, we update the exploration probability using \n",
    "    # espilon greedy algorithm\n",
    "    def update_exploration_probability(self):\n",
    "        self.exploration_proba = self.exploration_proba * np.exp(-self.exploration_proba_decay)\n",
    "        print(self.exploration_proba)\n",
    "\n",
    "    # At each time step, we store the corresponding experience\n",
    "    def store_episode(self,current_state, action, reward, next_state, done):\n",
    "        #We use a dictionnary to store them\n",
    "        self.memory_buffer.append({\n",
    "            \"current_state\":current_state,\n",
    "            \"action\":action,\n",
    "            \"reward\":reward,\n",
    "            \"next_state\":next_state,\n",
    "            \"done\" :done\n",
    "        })\n",
    "        # If the size of memory buffer exceeds its maximum, we remove the oldest experience\n",
    "        if len(self.memory_buffer) > self.max_memory_buffer:\n",
    "            self.memory_buffer.pop(0)\n",
    "\n",
    "    # At the end of each episode, we train our model\n",
    "    def train(self):\n",
    "        # We shuffle the memory buffer and select a batch size of experiences\n",
    "        np.random.shuffle(self.memory_buffer)\n",
    "        batch_sample = self.memory_buffer[0:self.batch_size]\n",
    "        \n",
    "        # We iterate over the selected experiences\n",
    "        for experience in batch_sample:\n",
    "            # We compute the Q-values of S_t\n",
    "            q_current_state = self.model.predict(experience[\"current_state\"])\n",
    "            # We compute the Q-target using Bellman optimality equation\n",
    "            q_target = experience[\"reward\"]\n",
    "            if not experience[\"done\"]:\n",
    "                q_target = q_target + self.gamma*np.max(self.model.predict(experience[\"next_state\"])[0])\n",
    "            q_current_state[0][experience[\"action\"]] = q_target\n",
    "            # train the model\n",
    "            self.model.fit(experience[\"current_state\"], q_current_state, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_move(actions, state, agent):\n",
    "    # start by running an episode for the first move:\n",
    "    eps = 0.01\n",
    "    r = random.uniform(0, 1)\n",
    "    if r <= eps: # epsilon greedy algorithm\n",
    "        move = random.choice(actions)\n",
    "    else:\n",
    "        # the parameterized policy will select the move, given the state (board, bag, played, etc.)\n",
    "        moveagent.compute_action(state)\n",
    "        \n",
    "    return move\n",
    "\n",
    "############################################################################################\n",
    "# Function: state_vectorize\n",
    "# inputs: board\n",
    "# reasoning: to take the board which is in proprietery state, and change it to a matrix of \n",
    "# size (columns, rows, # of letters)\n",
    "# This is to be then fed into the DQN neural network evaluation\n",
    "# output: state, size of (15, 15, 26)\n",
    "############################################################################################\n",
    "\n",
    "def state_vectorize(board):\n",
    "    rows, cols, n = (15, 15, 26) # declare size of the matrix: (#rows, #cols, #letters)\n",
    "    vec = [[[0 for k in range(n)] for j in range(rows)] for i in range(cols)]\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if board.square(i, j)._tile: # If this tile has a letter...\n",
    "                vec[i][j][ord(board.square(i, j)._tile) - 65] = 1 # One hot encode to the appropriate location\n",
    "                # e.g.: if 'A' is at top left corner:\n",
    "                # i = 0, j = 0\n",
    "                # ord(board.square(0, 0)._tile) - 65 = 0.\n",
    "                # So we set the position (0, 0, 0) to be 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = 234 # Our feature vector is 234 elements\n",
    "action_size = 20 # We are choosing from 20 actions\n",
    "n_episodes = 400 \n",
    "max_iteration_ep = 500 \n",
    "agent = DQNAgent(state_size, action_size)\n",
    "total_steps = 0\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "-102\n",
      "-141\n",
      "7\n",
      "76\n",
      "-113\n",
      "132\n",
      "-52\n",
      "-131\n",
      "-19\n",
      "17\n",
      "-58\n",
      "-29\n",
      "-86\n",
      "-46\n",
      "-15\n",
      "24\n",
      "-47\n",
      "5\n",
      "-57\n",
      "218\n",
      "16\n",
      "-107\n",
      "-82\n",
      "-156\n",
      "-57\n",
      "47\n",
      "-23\n",
      "4\n",
      "172\n",
      "53\n",
      "28\n",
      "-4\n",
      "-16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m             rack1 \u001b[39m=\u001b[39m rack1\u001b[39m.\u001b[39mreplace(rack1[l], bag\u001b[39m.\u001b[39mpop(), \u001b[39m1\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[39m# Opponents turn:\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m moves \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39;49mfind_best_moves(rack2, num\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m moves:\n\u001b[1;32m     40\u001b[0m     game\u001b[39m.\u001b[39mplay(moves[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstart_square,moves[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mword, moves[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdirection)\n",
      "File \u001b[0;32m~/Documents/GitHub/scrabbler/scrabbler/scrabbler.py:110\u001b[0m, in \u001b[0;36mGame.find_best_moves\u001b[0;34m(self, rack, num)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     across_moves \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboard\u001b[39m.\u001b[39mfind_best_moves(rack, \u001b[39m\"\u001b[39m\u001b[39macross\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdictionary, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtiles)\n\u001b[0;32m--> 110\u001b[0m     down_moves \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboard\u001b[39m.\u001b[39;49mfind_best_moves(rack, \u001b[39m\"\u001b[39;49m\u001b[39mdown\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdictionary, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtiles)\n\u001b[1;32m    111\u001b[0m     moves \u001b[39m=\u001b[39m across_moves \u001b[39m+\u001b[39m down_moves\n\u001b[1;32m    113\u001b[0m moves\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m move_: move_\u001b[39m.\u001b[39mscore, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/GitHub/scrabbler/scrabbler/scrabbler.py:356\u001b[0m, in \u001b[0;36mBoard.find_best_moves\u001b[0;34m(self, rack, direction, dictionary, tile_set)\u001b[0m\n\u001b[1;32m    354\u001b[0m         current \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset(left_most, direction, j)\n\u001b[1;32m    355\u001b[0m         \u001b[39mif\u001b[39;00m is_anchor(current):\n\u001b[0;32m--> 356\u001b[0m             moves\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_moves(current, direction, rack, dictionary, tile_set, anchors_used))\n\u001b[1;32m    357\u001b[0m             anchors_used\u001b[39m.\u001b[39mappend(current)\n\u001b[1;32m    358\u001b[0m \u001b[39mreturn\u001b[39;00m moves\n",
      "File \u001b[0;32m~/Documents/GitHub/scrabbler/scrabbler/scrabbler.py:331\u001b[0m, in \u001b[0;36mBoard.generate_moves\u001b[0;34m(self, anchor, direction, rack, dictionary, tile_set, anchors_used)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[39mreturn\u001b[39;00m word_score_\n\u001b[1;32m    330\u001b[0m initial_arc \u001b[39m=\u001b[39m Arc(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, dictionary\u001b[39m.\u001b[39mroot)\n\u001b[0;32m--> 331\u001b[0m gen(\u001b[39m0\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, deepcopy(rack), initial_arc, [], [])\n\u001b[1;32m    333\u001b[0m \u001b[39mreturn\u001b[39;00m plays\n",
      "File \u001b[0;32m~/Documents/GitHub/scrabbler/scrabbler/scrabbler.py:220\u001b[0m, in \u001b[0;36mBoard.generate_moves.<locals>.gen\u001b[0;34m(pos_, word_, rack_, arc_, new_tiles_, wild_cards_)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mif\u001b[39;00m tile_:\n\u001b[1;32m    219\u001b[0m     new_tiles_ \u001b[39m=\u001b[39m deepcopy(new_tiles_)\n\u001b[0;32m--> 220\u001b[0m     go_on(pos_, tile_, word_, rack_, arc_\u001b[39m.\u001b[39;49mget_next(tile_), arc_, new_tiles_, wild_cards_)\n\u001b[1;32m    221\u001b[0m \u001b[39melif\u001b[39;00m rack_:\n\u001b[1;32m    222\u001b[0m     other_direction \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdown\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m direction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39macross\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39macross\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/scrabbler/scrabbler/scrabbler.py:261\u001b[0m, in \u001b[0;36mBoard.generate_moves.<locals>.go_on\u001b[0;34m(pos_, char_, word_, rack_, new_arc_, old_arc_, new_tiles_, wild_cards_)\u001b[0m\n\u001b[1;32m    259\u001b[0m         new_arc_ \u001b[39m=\u001b[39m new_arc_\u001b[39m.\u001b[39mget_next(DELIMITER)\n\u001b[1;32m    260\u001b[0m         \u001b[39mif\u001b[39;00m new_arc_ \u001b[39mand\u001b[39;00m left_good \u001b[39mand\u001b[39;00m right_side_square:\n\u001b[0;32m--> 261\u001b[0m             gen(\u001b[39m1\u001b[39;49m, word_, rack_, new_arc_, new_tiles_, wild_cards_)\n\u001b[1;32m    262\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     word_ \u001b[39m=\u001b[39m word_ \u001b[39m+\u001b[39m char_\n",
      "File \u001b[0;32m~/Documents/GitHub/scrabbler/scrabbler/scrabbler.py:223\u001b[0m, in \u001b[0;36mBoard.generate_moves.<locals>.gen\u001b[0;34m(pos_, word_, rack_, arc_, new_tiles_, wild_cards_)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39melif\u001b[39;00m rack_:\n\u001b[1;32m    222\u001b[0m     other_direction \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdown\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m direction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39macross\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39macross\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mfor\u001b[39;00m letter_ \u001b[39min\u001b[39;00m (x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(rack_) \u001b[39mif\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msquare(\u001b[39m*\u001b[39mcoordinate_)\u001b[39m.\u001b[39mcross_set(other_direction)):\n\u001b[1;32m    224\u001b[0m         tmp_rack_ \u001b[39m=\u001b[39m deepcopy(rack_)\n\u001b[1;32m    225\u001b[0m         tmp_rack_\u001b[39m.\u001b[39mremove(letter_)\n",
      "File \u001b[0;32m~/Documents/GitHub/scrabbler/scrabbler/scrabbler.py:223\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39melif\u001b[39;00m rack_:\n\u001b[1;32m    222\u001b[0m     other_direction \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdown\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m direction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39macross\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39macross\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mfor\u001b[39;00m letter_ \u001b[39min\u001b[39;00m (x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(rack_) \u001b[39mif\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msquare(\u001b[39m*\u001b[39;49mcoordinate_)\u001b[39m.\u001b[39mcross_set(other_direction)):\n\u001b[1;32m    224\u001b[0m         tmp_rack_ \u001b[39m=\u001b[39m deepcopy(rack_)\n\u001b[1;32m    225\u001b[0m         tmp_rack_\u001b[39m.\u001b[39mremove(letter_)\n",
      "File \u001b[0;32m~/Documents/GitHub/scrabbler/scrabbler/scrabbler.py:176\u001b[0m, in \u001b[0;36mBoard.square\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msquare\u001b[39m(\u001b[39mself\u001b[39m, row, col):\n\u001b[1;32m    175\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"gets the square on the given coordinate, return None if out of bounds\"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(index \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m [row, col]):\n\u001b[1;32m    177\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     index \u001b[39m=\u001b[39m row \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m+\u001b[39m col\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(n_episodes):\n",
    "    bag = bag_o.copy()\n",
    "    random.shuffle(bag)\n",
    "    score1 = 0  # resetting the scores and bag:\n",
    "    score2 = 0\n",
    "    game = sc.Game(filename=\"/Users/sbrosh1/Documents/GitHub/scrabbler/games/start_state.p\",\n",
    "                   global_dictionary=global_dictionary, enable_logger=False)\n",
    "\n",
    "    rack1 = \"\"\n",
    "    rack2 = \"\"\n",
    "    for _ in range(RACK_MAX):\n",
    "        rack1 = rack1 + bag.pop()\n",
    "        rack2 = rack2 + bag.pop()\n",
    "\n",
    "    while len(bag) > 0:\n",
    "        moves = game.find_best_moves(rack1, num=20)\n",
    "        if moves:\n",
    "            move = choose_move(moves)\n",
    "            game.play(move.start_square, move.word, move.direction)\n",
    "            score1 = score1 + move.score\n",
    "            if move.score > 100:\n",
    "                print(\"SCORE: \", move.score)\n",
    "                print(\"MOVE: \", move.word)\n",
    "            for i in range(len(move.word)):\n",
    "                if len(bag) > 0:\n",
    "                    rack1 = rack1.replace(move.word[i], bag.pop(), 1)\n",
    "                else:\n",
    "                    rack1 = rack1.replace(move.word[i], '', 1)\n",
    "\n",
    "        else:\n",
    "            for l in range(len(rack1)):\n",
    "                if LETTER_VALUE[rack1[l]] > 4:\n",
    "                    bag.append(rack1[l])\n",
    "                    random.shuffle(bag)\n",
    "                    rack1 = rack1.replace(rack1[l], bag.pop(), 1)\n",
    "\n",
    "        # Opponents turn:\n",
    "        moves = game.find_best_moves(rack2, num=20)\n",
    "        if moves:\n",
    "            game.play(moves[0].start_square,moves[0].word, moves[0].direction)\n",
    "            score2 = score2 + moves[0].score\n",
    "\n",
    "            for i in range(len(moves[0].word)):\n",
    "                if len(bag) > 0:\n",
    "                    rack2 = rack2.replace(moves[0].word[i], bag.pop(), 1)\n",
    "                else:\n",
    "                    rack2 = rack2.replace(moves[0].word[i], '', 1)\n",
    "\n",
    "        else:\n",
    "            for l in range(len(rack2)):\n",
    "                if LETTER_VALUE[rack2[l]] > 4:\n",
    "                    bag.append(rack2[l])\n",
    "                    random.shuffle(bag)\n",
    "                    rack2 = rack2.replace(rack2[l], bag.pop(), 1)\n",
    "\n",
    "    print(score1 - score2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cart_pole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
